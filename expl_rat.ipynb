{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac33b78e-9a38-47ce-be72-6bd55f6538c8",
   "metadata": {},
   "source": [
    "# Import, filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa74c1f-f209-4cec-ab58-4f0cea68e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace1377-dd1d-4fb3-8a4d-304edce44af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "raw_data_df = pd.read_csv(\"data-compas/compas-scores-two-years.csv\")\n",
    "raw_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b454d36-9b75-424c-a62d-dabc4b229718",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2c93-d7a6-4a65-8eea-6bca76e048e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the dataset similarly to the way ProPublica did\n",
    "# see: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "filter_data_df = raw_data_df\n",
    "filter_data_df = filter_data_df[filter_data_df['days_b_screening_arrest'] >= -30]\n",
    "filter_data_df = filter_data_df[filter_data_df['days_b_screening_arrest'] <= 30]\n",
    "filter_data_df = filter_data_df[filter_data_df['is_recid'] != -1]\n",
    "filter_data_df = filter_data_df[filter_data_df['c_charge_degree'] != 'O']\n",
    "filter_data_df = filter_data_df[filter_data_df['score_text'] != 'N/A']\n",
    "filter_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990af3cb-d4d1-4287-baa2-535a78d6a8a3",
   "metadata": {},
   "source": [
    "## Split data into \"training\", \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a59a2b-0f66-4c3c-b0ca-37b675350a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "\n",
    "filter_data_df_src = filter_data_df.sample(n=int(split_ratio*len(filter_data_df)))\n",
    "filter_data_df_test = filter_data_df[~filter_data_df.index.isin(filter_data_df_src.index)]\n",
    "\n",
    "print(filter_data_df_src.shape)\n",
    "print(filter_data_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f5b4d-79c8-457a-868f-d539945a8a3c",
   "metadata": {},
   "source": [
    "# Define rationalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b44505-851d-40d9-803d-bf9c1c9efed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields accessible to use in rationalization?\n",
    "# ... some of which are VERY unfair\n",
    "accessible_fields = [\n",
    "    # 'sex', # >:(\n",
    "    # 'race', # >:(\n",
    "    'age',\n",
    "    'age_cat',\n",
    "    'juv_fel_count',\n",
    "    'decile_score',\n",
    "    'juv_misd_count',\n",
    "    'juv_other_count',\n",
    "    'priors_count',\n",
    "    'c_charge_degree',\n",
    "    'c_charge_desc',\n",
    "]\n",
    "# Field we are trying to rationalize why it could be 1 vs 0\n",
    "justifying_field = 'is_recid' # 'is_recid' or 'is_violent_recid'\n",
    "# Field that is the actual data for what we are trying to determine\n",
    "trueresult_field = 'two_year_recid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956c90b-f4a7-400d-bc39-ddf36d0f760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import proportion\n",
    "\n",
    "def rationalize(target, data_df, numfields=1):\n",
    "    def noIntervalOverlap(a1, a2, b1, b2):\n",
    "        if a1>a2 or b1>b2:\n",
    "            raise ValueError('unexpected bounds')\n",
    "        if a2<b1 and a1<b1:\n",
    "            return True\n",
    "        if b2<a1 and b1<a1:\n",
    "            return True\n",
    "        return False\n",
    "    breakdown = data_df[trueresult_field]\n",
    "    full_interval = proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta')\n",
    "    result_df = pd.DataFrame()\n",
    "    field_groups = [[i] for i in range(len(accessible_fields))]\n",
    "    for _ in range(numfields-1):\n",
    "        field_groups = [[f+[i] for i in range(len(accessible_fields)) if i>f[-1]] for f in field_groups]\n",
    "        field_groups = [e for l in field_groups for e in l]\n",
    "    for field_ids in field_groups:\n",
    "        field_names = [accessible_fields[i] for i in field_ids]\n",
    "        subgroup = data_df\n",
    "        for field in field_names:\n",
    "            subgroup = subgroup[subgroup[field] == target[field]]\n",
    "        subgroup_alt = data_df[~data_df.index.isin(subgroup.index)]\n",
    "        breakdown = subgroup[trueresult_field]\n",
    "        breakdown_alt = subgroup_alt[trueresult_field]\n",
    "        if len(breakdown)>0:\n",
    "            conf_interval = proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta')\n",
    "            altg_interval = proportion.proportion_confint(sum(breakdown_alt), len(breakdown_alt), alpha=0.05, method='beta')\n",
    "            result_df = result_df.append({\n",
    "                'id': target['id'],\n",
    "                'field_count': len(field_names),\n",
    "                'fields': field_names,\n",
    "                'fields_key': (tuple(field_names), tuple([target[fn] for fn in field_names])),\n",
    "                'sample_size': len(breakdown),\n",
    "                'percent_recid': sum(breakdown) / len(breakdown),\n",
    "                'percent_recid_alt': sum(breakdown_alt) / len(breakdown_alt),\n",
    "                # Confidence interval: in 95% of cases, the true underlying fraction of recidivism will fall within this interval\n",
    "                # https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval\n",
    "                # https://www.statsmodels.org/devel/generated/statsmodels.stats.proportion.proportion_confint.html\n",
    "                'conf_95_bot': conf_interval[0],\n",
    "                'conf_95_top': conf_interval[1],\n",
    "                # Statistical significance\n",
    "                'significant_baseline': 1 if noIntervalOverlap(conf_interval[0], conf_interval[1], full_interval[0], full_interval[1]) else 0,\n",
    "                'significant_altgroup': 1 if noIntervalOverlap(conf_interval[0], conf_interval[1], altg_interval[0], altg_interval[1]) else 0,\n",
    "            }, ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b6e88-2b34-4f6c-a182-169a5fe90e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdown = filter_data_df_src[trueresult_field]\n",
    "print('true recidivism (training):', sum(breakdown)/len(breakdown))\n",
    "print('true recidivism (training) range:', proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta'))\n",
    "\n",
    "print()\n",
    "\n",
    "breakdown = filter_data_df_test[trueresult_field]\n",
    "print('true recidivism (testing):', sum(breakdown)/len(breakdown))\n",
    "print('true recidivism (testing) range:', proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3b85d-9e8c-483b-a3ec-08cd5c6a01da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mini-example of selecting someone to justify both-sides of\n",
    "target = filter_data_df[filter_data_df['id'] == 2680].iloc[0] # filter_data_df.sample(n=1).iloc[0]\n",
    "filter_data_df[filter_data_df['id'] == target['id']]\n",
    "\n",
    "rationalize_df = pd.DataFrame()\n",
    "for numfields in [1,2,3]:\n",
    "    rationalize_df = rationalize_df.append(\n",
    "        rationalize(target, filter_data_df_src, numfields=numfields),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# rationalize_df.sort_values(['significant_baseline', 'percent_recid'])\n",
    "rationalize_df[rationalize_df['significant_baseline'] == 1].sort_values('percent_recid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06067577-4283-4cf8-bf30-515545c53197",
   "metadata": {},
   "source": [
    "# Visualize small sample of rationalization bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac396f4b-d5f5-403e-b220-996753542b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count_bothsides = 10\n",
    "count_factors = 3\n",
    "\n",
    "def vis(filter_data_df_src, filter_data_df_test, count_bothsides, count_factors):\n",
    "    plt.rcParams['figure.figsize'] = [15, 5]\n",
    "    gap_size = 10\n",
    "    \n",
    "    # Randomly select someone to justify negative pred for\n",
    "    for n in range(count_bothsides):\n",
    "        target = filter_data_df_test[filter_data_df_test[justifying_field] == 0].sample(n=1).iloc[0]\n",
    "        rationalize_df = pd.DataFrame()\n",
    "        for numfields in range(1, count_factors+1):\n",
    "            rationalize_df = rationalize_df.append(\n",
    "                rationalize(target, filter_data_df_src, numfields=numfields),\n",
    "                ignore_index=True\n",
    "            )\n",
    "        rationalize_df = rationalize_df[rationalize_df['significant_baseline'] == 1]\n",
    "        dots = plt.scatter(\n",
    "            [(2*i)+(2*count_factors*n) for i in rationalize_df['field_count']],\n",
    "            rationalize_df['percent_recid'], \n",
    "            alpha=[(i/max(rationalize_df['sample_size']))**0.9 for i in rationalize_df['sample_size']]\n",
    "        )\n",
    "        for i in range(1, count_factors+1):\n",
    "            temp_df = rationalize_df[rationalize_df['field_count']==i]\n",
    "            range_lo = min(temp_df['conf_95_top'])\n",
    "            range_hi = max(temp_df['conf_95_bot'])\n",
    "            pos_x = (2*i)+(2*count_factors*n)+1\n",
    "            marker = 'o' if (range_lo<=range_hi) else ''\n",
    "            _ = plt.plot(\n",
    "                [pos_x,pos_x], \n",
    "                [range_lo,range_hi],\n",
    "                color=dots.get_facecolors()[0][:-1],\n",
    "                marker=marker,\n",
    "            )\n",
    "\n",
    "    # Randomly select someone to justify positive pred for\n",
    "    for n in range(count_bothsides):\n",
    "        target = filter_data_df_test[filter_data_df_test[justifying_field] == 1].sample(n=1).iloc[0]\n",
    "        rationalize_df = pd.DataFrame()\n",
    "        for numfields in range(1, count_factors+1):\n",
    "            rationalize_df = rationalize_df.append(\n",
    "                rationalize(target, filter_data_df_src, numfields=numfields),\n",
    "                ignore_index=True\n",
    "            )\n",
    "        rationalize_df = rationalize_df[rationalize_df['significant_baseline'] == 1]\n",
    "        dots = plt.scatter(\n",
    "            [(2*i)+(2*count_factors*n)+(2*count_factors*count_bothsides)+gap_size for i in rationalize_df['field_count']], \n",
    "            rationalize_df['percent_recid'], \n",
    "            alpha=[(i/max(rationalize_df['sample_size']))**0.9 for i in rationalize_df['sample_size']]\n",
    "        )\n",
    "        for i in range(1, count_factors+1):\n",
    "            temp_df = rationalize_df[rationalize_df['field_count']==i]\n",
    "            if len(temp_df)==0:\n",
    "                pass\n",
    "            if len(temp_df['conf_95_top'])==0:\n",
    "                print(temp_df)\n",
    "                raise ValueError()\n",
    "            range_lo = min(temp_df['conf_95_top'])\n",
    "            if len(temp_df['conf_95_bot'])==0:\n",
    "                print(temp_df)\n",
    "                raise ValueError()\n",
    "            range_hi = max(temp_df['conf_95_bot'])\n",
    "            pos_x = (2*i)+(2*count_factors*n)+(2*count_factors*count_bothsides)+gap_size+1\n",
    "            marker = 'o' if (range_lo<=range_hi) else ''\n",
    "            _ = plt.plot(\n",
    "                [pos_x,pos_x], \n",
    "                [range_lo,range_hi],\n",
    "                color=dots.get_facecolors()[0][:-1],\n",
    "                marker=marker,\n",
    "            )\n",
    "    \n",
    "    # population mean line\n",
    "    breakdown = filter_data_df_src[trueresult_field]\n",
    "    src_range = proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta')\n",
    "    plt.axline((1, sum(breakdown)/len(breakdown)), slope=0, alpha=0.4)\n",
    "    plt.fill_between(\n",
    "        [0, 4*count_factors*count_bothsides+gap_size+2], \n",
    "        [src_range[1], src_range[1]], \n",
    "        [src_range[0], src_range[0]], \n",
    "        alpha=0.2\n",
    "    )\n",
    "    # 50% line\n",
    "    plt.axline((1, 0.5), slope=0, alpha=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb93cd2-9a0b-4962-95c9-e397bc44f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(filter_data_df_src, filter_data_df_test, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc003b-fe77-418f-8c20-83c01ca04238",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(filter_data_df_src, filter_data_df_test, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e644467-c229-418f-89ec-4bec4fe7ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(filter_data_df_src, filter_data_df_test, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5948f6-6af4-4b2a-8948-2625f5a28c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis(filter_data_df_src, filter_data_df_test, 20, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17989e-8eec-4148-9048-8e82dbf1ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis(filter_data_df_src, filter_data_df_test, 20, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbd8d9-6838-4863-960d-36f26fa5c539",
   "metadata": {},
   "source": [
    "# Calculate rationalization for ALL test set samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdef0eb-4670-4891-93bd-82f01d6c1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rationalization for all test set samples\n",
    "\n",
    "count_factors = 2\n",
    "\n",
    "test_rationalizations = pd.DataFrame()\n",
    "for _, case in filter_data_df_test.iterrows():\n",
    "    for numfields in range(1, count_factors+1):\n",
    "        test_rationalizations = pd.concat(\n",
    "            [\n",
    "                test_rationalizations,\n",
    "                rationalize(case, filter_data_df_src, numfields=numfields),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "# Add column representing the 'side' that each rationalization is in favor of\n",
    "breakdown = filter_data_df_src[trueresult_field]\n",
    "justifying_ref_avg = sum(breakdown)/len(breakdown)\n",
    "test_rationalizations['is_recid_rat_side'] = test_rationalizations.apply(lambda r: 1 if r['percent_recid']>justifying_ref_avg else 0, axis=1)\n",
    "\n",
    "test_rationalizations[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20054469-a220-4a17-a912-f10e5abf650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence interval of entire training dataset\n",
    "breakdown = filter_data_df_src[trueresult_field]\n",
    "src_range = proportion.proportion_confint(sum(breakdown), len(breakdown), alpha=0.05, method='beta')\n",
    "src_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b5702-fb14-41dd-9a97-7e69e83f96f1",
   "metadata": {},
   "source": [
    "# Visualize all test-set results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6adcce-dd8b-4468-80b1-645b4929f629",
   "metadata": {},
   "source": [
    "## Show distribution of confidence interval gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2c413-6657-4071-a24c-78c9422dacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_bins = 30\n",
    "\n",
    "# Compute and show confidence interval gaps between \"closest to justify 1\" vs \"closest to justify 0\"\n",
    "temp_gaps = []\n",
    "for x_id, x_rat in test_rationalizations.groupby(['id']):\n",
    "    range_lo = min(x_rat['conf_95_top'])\n",
    "    range_hi = max(x_rat['conf_95_bot'])\n",
    "    temp_gaps.append(range_hi-range_lo)\n",
    "\n",
    "_ = plt.hist(temp_gaps, bins=num_bins)\n",
    "_ = plt.title('all rats')\n",
    "plt.show()\n",
    "\n",
    "# CI gaps ... for size-1 sets\n",
    "temp_gaps = []\n",
    "for x_id, x_rat in test_rationalizations[test_rationalizations['field_count']==1].groupby(['id']):\n",
    "    range_lo = min(x_rat['conf_95_top'])\n",
    "    range_hi = max(x_rat['conf_95_bot'])\n",
    "    temp_gaps.append(range_hi-range_lo)\n",
    "\n",
    "_ = plt.hist(temp_gaps, bins=num_bins)\n",
    "_ = plt.title('rats f=1')\n",
    "plt.show()\n",
    "\n",
    "# CI gaps ... for size-2 sets\n",
    "temp_gaps = []\n",
    "for x_id, x_rat in test_rationalizations[test_rationalizations['field_count']==2].groupby(['id']):\n",
    "    range_lo = min(x_rat['conf_95_top'])\n",
    "    range_hi = max(x_rat['conf_95_bot'])\n",
    "    temp_gaps.append(range_hi-range_lo)\n",
    "\n",
    "_ = plt.hist(temp_gaps, bins=num_bins)\n",
    "_ = plt.title('rats f=2')\n",
    "plt.show()\n",
    "\n",
    "# Compute and show confidence interval gaps between \"closest to justify 1\" vs \"closest to justify 0\" for ONLY the significant sets (???)\n",
    "test_signif_rat = test_rationalizations[test_rationalizations['significant_baseline']==1]\n",
    "temp_gaps = []\n",
    "for x_id, x_rat in test_signif_rat.groupby(['id']):\n",
    "    range_lo = min(x_rat['conf_95_top'])\n",
    "    range_hi = max(x_rat['conf_95_bot'])\n",
    "    temp_gaps.append(range_hi-range_lo)\n",
    "\n",
    "_ = plt.hist(temp_gaps, bins=num_bins)\n",
    "_ = plt.title('iff-significant rats')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332a984-55db-4cd4-84e1-d45dac1489bb",
   "metadata": {},
   "source": [
    "## Show single-rat and double-rat cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267fabb-1046-4b8f-bb44-6001102de7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'id':[], 'ratted_single':[], 'ratted_double':[]}\n",
    "for x_id, x_rat in test_rationalizations[test_rationalizations['significant_baseline'] == 1].groupby(['id']):\n",
    "    tags['id'].append(x_id)\n",
    "    x_goal = filter_data_df_test[filter_data_df_test['id']==x_id].iloc[0][justifying_field]\n",
    "    # figure out if goal has been achieved to prediction case-by-case\n",
    "    tags['ratted_single'].append(any(x_rat['is_recid_rat_side']==x_goal))\n",
    "    # figure out if goal could be achievable either way case-by-case\n",
    "    rat_total = sum(x_rat['is_recid_rat_side'])\n",
    "    tags['ratted_double'].append(rat_total<len(x_rat['is_recid_rat_side']) and rat_total>0)\n",
    "test_ratsides = pd.DataFrame(tags)\n",
    "test_ratsides[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a366aff-88a9-4619-a954-efba0bccd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('successful rat single', sum(test_ratsides['ratted_single'])/len(test_ratsides))\n",
    "print('successful rat double', sum(test_ratsides['ratted_double'])/len(test_ratsides))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5a170-3a99-4d6e-9022-426eb49dfadc",
   "metadata": {},
   "source": [
    "# Do group multi-element rationalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef862fd-2b03-407c-a342-c934fc7729b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out every distinct set of field-value examinations that could be used for justification\n",
    "fields_keys_gb = test_rationalizations[test_rationalizations['significant_baseline']==1].merge(\n",
    "    filter_data_df_test[['id', justifying_field]], left_on='id', right_on='id'\n",
    ").groupby(\n",
    "    by=['fields_key']\n",
    ")\n",
    "\n",
    "fields_keys = pd.DataFrame()\n",
    "fields_keys['is_recid_rat_side'] = fields_keys_gb.apply(\n",
    "    lambda x: x['is_recid_rat_side'].mean()\n",
    ")\n",
    "fields_keys['is_recid_test_mean'] = fields_keys_gb.apply(\n",
    "    lambda x: x['is_recid'].mean()\n",
    ")\n",
    "fields_keys['samples'] = fields_keys_gb.apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "fields_keys['id_samples'] = fields_keys_gb.apply(\n",
    "    lambda x: list(x['id'])\n",
    ")\n",
    "fields_keys[:5]#.sort_values('samples').sort_values('is_recid_test_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68976d75-c9cc-4b79-9f5e-de52020f2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rationalizations[:5]\n",
    "\n",
    "temp_singlemerge = test_rationalizations.merge(filter_data_df_test[['id', justifying_field]], left_on='id', right_on='id')\n",
    "temp_singlemerge[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e0dd7-096a-47cf-8c06-d60e50b63040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
